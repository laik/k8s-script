删除osd的正确方式有如下(对比分析)

选第二种删除
 

在ceph的集群当中关于节点的替换的问题，一直按照以前的方式进行的处理，处理的步骤如下：

停止osd进程
/etc/init.d/ceph stop osd.0
这一步是停止osd的进程，让其他的osd知道这个节点不提供服务了


将节点状态标记为out
ceph osd out osd.0
这个一步是告诉mon，这个节点已经不能服务了，需要在其他的osd上进行数据的恢复了

将节点down 
ceph osd down osd.0

从crush中移除节点
ceph osd crush remove osd.0
从crush中删除是告诉集群这个点回不来了，完全从集群的分布当中剔除掉，让集群的crush进行一次重新计算，之前节点还占着这个crush weight，会影响到当前主机的host crush weight

删除节点
ceph osd rm osd.0
这个是从集群里面删除这个节点的记录

删除节点认证（不删除编号会占住）
ceph auth del osd.0
这个是从认证当中去删除这个节点的信息

这个一直是我处理故障的节点osd的方式，其实这个会触发两次迁移，一次是在节点osd out以后，一个是在crush remove以后，两次迁移对于集群来说是不好的，其实是调整步骤是可以避免二次迁移的

 

 

新的处理方式（推荐）
调整osd的crush weight
ceph osd crush reweight osd.0 0.1
说明：这个地方如果想慢慢的调整就分几次将crush 的weight 减低到0 ，这个过程实际上是让数据不分布在这个节点上，让数据慢慢的分布到其他节点上，直到最终为没有分布在这个osd，并且迁移完成
这个地方不光调整了osd 的crush weight ，实际上同时调整了host 的 weight ，这样会调整集群的整体的crush 分布，在osd 的crush 为0 后， 再对这个osd的任何删除相关操作都不会影响到集群的数据的分布

停止osd进程
/etc/init.d/ceph stop osd.0
停止到osd的进程，这个是通知集群这个osd进程不在了，不提供服务了，因为本身没权重，就不会影响到整体的分布，也就没有迁移

将节点状态标记为out
ceph osd out osd.0
停止到osd的进程，这个是通知集群这个osd不再映射数据了，不提供服务了，因为本身没权重，就不会影响到整体的分布，也就没有迁移

从crush中移除节点
ceph osd crush remove osd.0
这个是从crush中删除，因为已经是0了 所以没影响主机的权重，也就没有迁移了

删除节点
ceph osd rm osd.0
这个是从集群里面删除这个节点的记录

删除节点认证（不删除编号会占住）
ceph auth del osd.0
这个是从认证当中去删除这个节点的信息

经过验证，第二种方式只触发了一次迁移，虽然只是一个步骤先后上的调整，对于生产环境的的集群来说，迁移的量要少了一次，实际生产环境当中节点是有自动out的功能，这个可以考虑自己去控制，只是监控的密度需要加大，毕竟这个是一个需要监控的集群，完全让其自己处理数据的迁移是不可能的，带来的故障只会更多