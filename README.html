<!DOCTYPE html>
    <html>
    <head>
        <meta http-equiv="Content-type" content="text/html;charset=UTF-8">
        <style>
/*--------------------------------------------------------------------------------------------- * Copyright (c) Microsoft Corporation. All rights reserved. * Licensed under the MIT License. See License.txt in the project root for license information. *--------------------------------------------------------------------------------------------*/ body { font-family: "Segoe WPC", "Segoe UI", "SFUIText-Light", "HelveticaNeue-Light", sans-serif, "Droid Sans Fallback"; font-size: 14px; padding: 0 12px; line-height: 22px; word-wrap: break-word; } body.scrollBeyondLastLine { margin-bottom: calc(100vh - 22px); } body.showEditorSelection .code-line { position: relative; } body.showEditorSelection .code-active-line:before, body.showEditorSelection .code-line:hover:before { content: ""; display: block; position: absolute; top: 0; left: -12px; height: 100%; } body.showEditorSelection li.code-active-line:before, body.showEditorSelection li.code-line:hover:before { left: -30px; } .vscode-light.showEditorSelection .code-active-line:before { border-left: 3px solid rgba(0, 0, 0, 0.15); } .vscode-light.showEditorSelection .code-line:hover:before { border-left: 3px solid rgba(0, 0, 0, 0.40); } .vscode-dark.showEditorSelection .code-active-line:before { border-left: 3px solid rgba(255, 255, 255, 0.4); } .vscode-dark.showEditorSelection .code-line:hover:before { border-left: 3px solid rgba(255, 255, 255, 0.60); } .vscode-high-contrast.showEditorSelection .code-active-line:before { border-left: 3px solid rgba(255, 160, 0, 0.7); } .vscode-high-contrast.showEditorSelection .code-line:hover:before { border-left: 3px solid rgba(255, 160, 0, 1); } img { max-width: 100%; max-height: 100%; } a { color: #4080D0; text-decoration: none; } a:focus, input:focus, select:focus, textarea:focus { outline: 1px solid -webkit-focus-ring-color; outline-offset: -1px; } hr { border: 0; height: 2px; border-bottom: 2px solid; } h1 { padding-bottom: 0.3em; line-height: 1.2; border-bottom-width: 1px; border-bottom-style: solid; } h1, h2, h3 { font-weight: normal; } h1 code, h2 code, h3 code, h4 code, h5 code, h6 code { font-size: inherit; line-height: auto; } a:hover { color: #4080D0; text-decoration: underline; } table { border-collapse: collapse; } table > thead > tr > th { text-align: left; border-bottom: 1px solid; } table > thead > tr > th, table > thead > tr > td, table > tbody > tr > th, table > tbody > tr > td { padding: 5px 10px; } table > tbody > tr + tr > td { border-top: 1px solid; } blockquote { margin: 0 7px 0 5px; padding: 0 16px 0 10px; border-left: 5px solid; } code { font-family: Menlo, Monaco, Consolas, "Droid Sans Mono", "Courier New", monospace, "Droid Sans Fallback"; font-size: 14px; line-height: 19px; } body.wordWrap pre { white-space: pre-wrap; } .mac code { font-size: 12px; line-height: 18px; } code > div { padding: 16px; border-radius: 3px; overflow: auto; } /** Theming */ .vscode-light { color: rgb(30, 30, 30); } .vscode-dark { color: #DDD; } .vscode-high-contrast { color: white; } .vscode-light code { color: #A31515; } .vscode-dark code { color: #D7BA7D; } .vscode-light code > div { background-color: rgba(220, 220, 220, 0.4); } .vscode-dark code > div { background-color: rgba(10, 10, 10, 0.4); } .vscode-high-contrast code > div { background-color: rgb(0, 0, 0); } .vscode-high-contrast h1 { border-color: rgb(0, 0, 0); } .vscode-light table > thead > tr > th { border-color: rgba(0, 0, 0, 0.69); } .vscode-dark table > thead > tr > th { border-color: rgba(255, 255, 255, 0.69); } .vscode-light h1, .vscode-light hr, .vscode-light table > tbody > tr + tr > td { border-color: rgba(0, 0, 0, 0.18); } .vscode-dark h1, .vscode-dark hr, .vscode-dark table > tbody > tr + tr > td { border-color: rgba(255, 255, 255, 0.18); } .vscode-light blockquote, .vscode-dark blockquote { background: rgba(127, 127, 127, 0.1); border-color: rgba(0, 122, 204, 0.5); } .vscode-high-contrast blockquote { background: transparent; border-color: #fff; }
</style>
<style>
/* Tomorrow Theme */ /* http://jmblog.github.com/color-themes-for-google-code-highlightjs */ /* Original theme - https://github.com/chriskempson/tomorrow-theme */ /* Tomorrow Comment */ .hljs-comment, .hljs-quote { color: #8e908c; } /* Tomorrow Red */ .hljs-variable, .hljs-template-variable, .hljs-tag, .hljs-name, .hljs-selector-id, .hljs-selector-class, .hljs-regexp, .hljs-deletion { color: #c82829; } /* Tomorrow Orange */ .hljs-number, .hljs-built_in, .hljs-builtin-name, .hljs-literal, .hljs-type, .hljs-params, .hljs-meta, .hljs-link { color: #f5871f; } /* Tomorrow Yellow */ .hljs-attribute { color: #eab700; } /* Tomorrow Green */ .hljs-string, .hljs-symbol, .hljs-bullet, .hljs-addition { color: #718c00; } /* Tomorrow Blue */ .hljs-title, .hljs-section { color: #4271ae; } /* Tomorrow Purple */ .hljs-keyword, .hljs-selector-tag { color: #8959a8; } .hljs { display: block; overflow-x: auto; color: #4d4d4c; padding: 0.5em; } .hljs-emphasis { font-style: italic; } .hljs-strong { font-weight: bold; }
</style>
<style>
ul.contains-task-list { padding-left: 0; } ul ul.contains-task-list { padding-left: 40px; } .task-list-item { list-style-type: none; } .task-list-item-checkbox { vertical-align: middle; }
</style>
        <style>
            body {
                font-family: -apple-system, BlinkMacSystemFont, 'Segoe WPC', 'Segoe UI', 'HelveticaNeue-Light', 'Ubuntu', 'Droid Sans', sans-serif;
                font-size: 14px;
                line-height: 1.6;
            }
        </style>
    </head>
    <body>
        <h1 id="k8s-script">k8s-script</h1>
<h2 id="hosts-ip--node">配置 hosts 集群ip 信息(双主且都是 Node 测试环境)</h2>
<ul>
<li>创建版本 - v20180418</li>
<li>当前 K8s 版本 v1.10.1</li>
</ul>
<h4 id="vagrant-vm">Vagrant vm 机器列表(如果真实机器也是如此)</h4>
<table>
<thead>
<tr>
<th style="text-align:left">hosts</th>
<th style="text-align:left">ip</th>
<th style="text-align:left">delopy</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">node1</td>
<td style="text-align:left">192.168.33.41</td>
<td style="text-align:left">virtual ware</td>
</tr>
<tr>
<td style="text-align:left">node2</td>
<td style="text-align:left">192.168.33.42</td>
<td style="text-align:left">virtual ware</td>
</tr>
<tr>
<td style="text-align:left">node3</td>
<td style="text-align:left">192.168.33.43</td>
<td style="text-align:left">virtual ware</td>
</tr>
</tbody>
</table>
<h2 id="vagrantvirtualbox">Vagrant+Virtualbox</h2>
<p>[√] 下载 Vagrantfile</p>
<blockquote>
<p>curl <a href="https://raw.githubusercontent.com/laik/k8s-script/master/Vagrantfile">https://raw.githubusercontent.com/laik/k8s-script/master/Vagrantfile</a> &gt; Vagrantfile</p>
</blockquote>
<p>[√] 开始下载准备好的镜像(<code>tmp/k8s-dev.sh</code>需要修改里面的用户密码[自己去阿里云搞个用户])</p>
<blockquote>
<p>mkdir tmp &amp;&amp;
curl <a href="https://raw.githubusercontent.com/laik/k8s-script/master/k8s-dev.sh">https://raw.githubusercontent.com/laik/k8s-script/master/k8s-dev.sh</a> &gt; tmp/k8s-dev.sh</p>
</blockquote>
<p>[√] 启动 Vagrant</p>
<blockquote>
<p>vagrant up</p>
</blockquote>
<p>[√] 初始化kubernetes
第一次初始化失败已经存在配置文件,需要加 <code>--ignore-preflight-errors=all</code>(参数跟飞机起飞)</p>
<pre><code class="language-Shell"># 初始化获取当前版本
curl https://storage.googleapis.com/kubernetes-release/release/stable-1.10.txt


# 我们使用v1.10.1
kubeadm init --apiserver-advertise-address=192.168.33.41--kubernetes-version=v1.10.1 --pod-network-cidr=10.244.0.0/16


# 对于非root用户
$ mkdir -p $HOME/.kube
$ sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
$ sudo chown $(id -u):$(id -g) $HOME/.kube/config

# 对于root用户
$ export KUBECONFIG=/etc/kubernetes/admin.conf
# 也可以直接放到~/.bash_profile
$ echo "export KUBECONFIG=/etc/kubernetes/admin.conf" >> ~/.bashrc

# 默认情况下，为了保证master的安全，master是不会被调度到app的。你可以取消这个限制通过输入：
> kubectl taint nodes --all node-role.kubernetes.io/master-

# addons 
接下来要注意，我们必须自己来安装一个network addon。network addon必须在任何app部署之前安装好。同样的，kube-dns也会在network addon安装好之后才启动 kubeadm只支持CNI-based networks（不支持kubenet）。比较常见的network addon有：Calico, Canal, Flannel, Kube-router, Romana, Weave Net等。这里我们使用Calico。

# 用 weave net 安装方法
export kubever=$(kubectl version | base64 | tr -d '\n')
kubectl apply -f "https://cloud.weave.works/k8s/net?k8s-version=$kubever"
systemctl restart docker && systemctl restart kubelet

# 用 Calico 作为网络传输层
kubectl apply -f https://docs.projectcalico.org/v3.0/getting-started/kubernetes/installation/hosted/kubeadm/1.7/calico.yaml
systemctl restart docker && systemctl restart kubelet

# dashboard
kubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/master/src/deploy/recommended/kubernetes-dashboard.yaml
kubectl proxy
</code></pre>
<p>[√] 清除当前集群信息</p>
<pre><code>   kubeadm reset
</code></pre>
<p>Enjoy it!!</p>
<hr>
<p>[√] FQA(关于在部署的过程中遇到一些问题记录)</p>
<blockquote>
<ol>
<li>cni 问题 Container runtime network not ready: NetworkReady=false reason:NetworkPluginNotReady message:docker: network plugin is not ready: cni config uninitialized</li>
</ol>
<blockquote>
<p>删除 /etc/systemd/system/kubelet.service.d/10-kubeadm.conf 中的$ KUBELET_NETWORK_ARGS 参数之后执行
<code>systemctl daemon-reload &amp;&amp; systemctl restart kubelet</code></p>
</blockquote>
</blockquote>
<blockquote>
<ol start="2">
<li>https 访问 dashboard 证书问题</li>
</ol>
<blockquote>
<p>基于docker镜像部署方式</p>
<blockquote>
<p>source url from github [<a href="https://github.com/kubernetes/dashboard/wiki/Accessing-Dashboard---1.7.X-and-above">https://github.com/kubernetes/dashboard/wiki/Accessing-Dashboard---1.7.X-and-above</a>]</p>
<p>This way of accessing Dashboard is only recommended for development environments in a single node setup.</p>
<p>Edit kubernetes-dashboard service.</p>
<pre><code>$ kubectl -n kube-system edit service kubernetes-dashboard
</code></pre>
<p>You should see yaml representation of the service. Change type: ClusterIP to type: NodePort and save file. If it's already changed go to next step.</p>
<p>Please edit the object below. Lines beginning with a '#' will be ignored,
and an empty file will abort the edit. If an error occurs while saving this file will be</p>
<h4 id="reopened-with-the-relevant-failures">reopened with the relevant failures.</h4>
<pre><code>apiVersion: v1
...
  name: kubernetes-dashboard
  namespace: kube-system
  resourceVersion: "343478"
  selfLink: /api/v1/namespaces/kube-system/services/kubernetes-dashboard-head
  uid: 8e48f478-993d-11e7-87e0-901b0e532516
spec:
  clusterIP: 10.100.124.90
  externalTrafficPolicy: Cluster
  ports:
  - port: 443
    protocol: TCP
    targetPort: 8443
  selector:
    k8s-app: kubernetes-dashboard
  sessionAffinity: None
  type: ClusterIP
status:
  loadBalancer: {}
</code></pre>
<p>Next we need to check port on which Dashboard was exposed.</p>
<pre><code>$ kubectl -n kube-system get service kubernetes-dashboard
</code></pre>
<pre><code>NAME                   CLUSTER-IP       EXTERNAL-IP   PORT(S)        AGE
kubernetes-dashboard   10.100.124.90   <nodes>       443:31707/TCP   21h
Dashboard has been exposed on port 31707 (HTTPS). Now you can access it from your browser at: https://<master-ip>:31707. master-ip can be found by executing kubectl cluster-info. Usually it is either 127.0.0.1 or IP of your machine, assuming that your cluster is running directly on the machine, on which these commands are executed.
</code></pre>
<h4 id="1010012490-31707-system-serviceaccount-kube-system-kubernetes-dashboard">当改为节点访问10.100.124.90:31707 时会出现&quot;system:serviceaccount:kube-system:kubernetes-dashboard&quot;</h4>
<p>If you received an error like below, you need to grant access to Kubernetes dashboard to in your cluster.</p>
<p>configmaps is forbidden: User &quot;system:serviceaccount:kube-system:kubernetes-dashboard&quot; cannot list configmaps in the namespace &quot;default&quot;</p>
<p>If you are planning to access to Kubernetes Dashboard via proxy from remote machine, you will need to grant ClusterRole to allow access to dashboard.</p>
<p>Create new file and insert following details.</p>
<pre><code>vi kube-dashboard-access.yaml
</code></pre>
<pre><code>apiVersion: rbac.authorization.k8s.io/v1beta1
kind: ClusterRoleBinding
metadata:
  name: kubernetes-dashboard
  labels:
    k8s-app: kubernetes-dashboard
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: cluster-admin
subjects:
- kind: ServiceAccount
  name: kubernetes-dashboard
  namespace: kube-system
</code></pre>
<p>Now we will apply changes to Kubernetes Cluster to grant access to dashboard.</p>
<pre><code>kubectl create -f kube-dashboard-access.yaml
</code></pre>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<h4 id="">二进制部署的改造方法(没试过)</h4>
<blockquote>
<h5 id="kubernetes-api-server-anonymous-auth-secure-portauthenticationanonymous-requests-usernamesystem-anonymous--system-unauthenticatedchromedashboard-uiauthorization-anonymous-auth--false">Kubernetes API Server新增了 –anonymous-auth 选项，允许匿名请求访问secure port。没有被其他authentication方法拒绝的请求即Anonymous requests， 这样的匿名请求的username为system:anonymous, 归属的组为system:unauthenticated。并且该选线是默认的。这样一来，当采用chrome浏览器访问dashboard UI时很可能无法弹出用户名、密码输入对话框，导致后续authorization失败。为了保证用户名、密码输入对话框的弹出，需要将 –anonymous-auth 设置为 false。</h5>
<h4 id="1">解决方法1：</h4>
<p>在api-server配置文件中添加 –anonymous-auth=false</p>
<pre><code>[root@master1 dashboard]# vim /etc/systemd/system/kube-apiserver.service
</code></pre>
<pre><code>[Unit]
Description=Kubernetes API Server
Documentation=https://github.com/GoogleCloudPlatform/kubernetes
After=network.target
After=etcd.service

[Service]
ExecStart=/usr/local/bin/kube-apiserver \
  --logtostderr=true \
  --admission-control=NamespaceLifecycle,LimitRanger,ServiceAccount,DefaultStorageClass,ResourceQuota,NodeRestriction \
  --advertise-address=192.168.161.161 \
  --bind-address=192.168.161.161 \
  --insecure-bind-address=127.0.0.1 \
  --authorization-mode=Node,RBAC \
  --anonymous-auth=false \
  --basic-auth-file=/etc/kubernetes/basic_auth_file \
  --runtime-config=rbac.authorization.k8s.io/v1alpha1 \
  --kubelet-https=true \
  --enable-bootstrap-token-auth \
  --token-auth-file=/etc/kubernetes/token.csv \
  --service-cluster-ip-range=10.254.0.0/16 \
  --service-node-port-range=8400-10000 \
  --tls-cert-file=/etc/kubernetes/ssl/kubernetes.pem \
  --tls-private-key-file=/etc/kubernetes/ssl/kubernetes-key.pem \
  --client-ca-file=/etc/kubernetes/ssl/ca.pem \
  --service-account-key-file=/etc/kubernetes/ssl/ca-key.pem \
  --etcd-cafile=/etc/kubernetes/ssl/ca.pem \
  --etcd-certfile=/etc/kubernetes/ssl/kubernetes.pem \
  --etcd-keyfile=/etc/kubernetes/ssl/kubernetes-key.pem \
  --etcd-servers=https://192.168.161.161:2379,https://192.168.161.162:2379,https://192.168.161.163:2379 \
  --enable-swagger-ui=true \
  --allow-privileged=true \
  --apiserver-count=3 \
  --audit-log-maxage=30 \
  --audit-log-maxbackup=3 \
  --audit-log-maxsize=100 \
  --audit-log-path=/var/lib/audit.log \
  --event-ttl=1h \
  --v=2
Restart=on-failure
RestartSec=5
Type=notify
LimitNOFILE=65536

[Install]
WantedBy=multi-user.target
</code></pre>
<h4 id="unauthorized">Unauthorized问题</h4>
<p>解决了上面那个问题之后，再度访问dashboard页面，发现还是有问题，出现下面这个问题：</p>
<pre><code>{
  "kind": "Status",
  "apiVersion": "v1",
  "metadata": {

  },
  "status": "Failure",
  "message": "Unauthorized",
  "reason": "Unauthorized",
  "code": 401
}
</code></pre>
<p>解决方法1：
新建 /etc/kubernetes/basic_auth_file 文件，并在其中添加：</p>
<p>admin123,admin,1002
文件内容格式：password,username,uid</p>
<p>然后在api-server配置文件（即上面的配置文件）中添加：</p>
<pre><code>--basic-auth-file=/etc/kubernetes/basic_auth_file \
</code></pre>
<h4 id="kube-apiserver">保存重启kube-apiserver：</h4>
<pre><code>systemctl daemon-reload
systemctl restart kube-apiserver
systemctl status kube-apiserver
最后在kubernetes上执行下面这条命令：
</code></pre>
<pre><code>kubectl create clusterrolebinding login-dashboard-admin --clusterrole=cluster-admin --user=admin
</code></pre>
<p>将访问账号名admin与dashboard.yaml文件中指定的cluster-admin关联，获得访问权限。</p>
<h4 id="2">解决方法2:</h4>
<pre><code>nohup kubectl proxy --accept-hosts='^*$' > /tmp/proxy.log 2>&1 &
</code></pre>
</blockquote>
</blockquote>
</blockquote>
<blockquote>
<h4 id="3-failed-to-create-summary-reader-for--systemslice-auditdservice--none-of-the-resources-are-being-tracked">3. 关于&quot;Failed to create summary reader for &quot;/system.slice/auditd.service&quot;: none of the resources are being tracked.&quot;</h4>
<blockquote>
<h5 id="etc-systemd-system-kubeletserviced-10-kubeadmconf-environmentkubelet-cgroup-args--cgroup-drivercgroupfs---runtime-cgroups-systemd-systemslice---kubelet-cgroups-systemd-systemslice----runtime-cgroups-systemd-systemslice---kubelet-cgroups-systemd-systemslice">总结: 以下那么长的解释就是为了在 /etc/systemd/system/kubelet.service.d/10-kubeadm.conf Environment=&quot;KUBELET_CGROUP_ARGS=--cgroup-driver=cgroupfs --runtime-cgroups=/systemd/system.slice --kubelet-cgroups=/systemd/system.slice&quot; 加入后面 --runtime-cgroups=/systemd/system.slice --kubelet-cgroups=/systemd/system.slice 这一段</h5>
<h5 id="">---------------------分隔线------------------------------------------</h5>
<p>I've got the same errors on</p>
<p>CentOS 7.4.1708
docker 1.12.6
kubeadm v1.9.4
Mar 14 08:32:35 ksa-m1.blue kubelet[9322]: E0314 08:32:34.998853    9322 summary.go:92] Failed to get system container stats for &quot;/system.slice/kubelet.service&quot;: failed to get cgroup stats for &quot;/system.slice/kubelet.service&quot;: failed to get container info for &quot;/system.slice/kubelet.service&quot;: unknown container &quot;/system.slice/kubelet.service&quot;
Mar 14 08:32:35 ksa-m1.blue kubelet[9322]: E0314 08:32:34.998879    9322 summary.go:92] Failed to get system container stats for &quot;/system.slice/docker.service&quot;: failed to get cgroup stats for &quot;/system.slice/docker.service&quot;: failed to get container info for &quot;/system.slice/docker.service&quot;: unknown container &quot;/system.slice/docker.service&quot;
And the above fix works for me.
On CentOS I can add these options in /etc/systemd/system/kubelet.service.d/10-kubeadm.conf:</p>
<pre><code>egrep KUBELET_CGROUP_ARGS= /etc/systemd/system/kubelet.service.d/10-kubeadm.conf
</code></pre>
<pre><code>Environment="KUBELET_CGROUP_ARGS=--cgroup-driver=cgroupfs --runtime-cgroups=/systemd/system.slice --kubelet-cgroups=/systemd/system.slice"
</code></pre>
<p>Should we have this fix added to the kubeadm RPM by default?
Environment:</p>
<p>cat /etc/redhat-release
CentOS Linux release 7.4.1708 (Core)</p>
<p>uname -a
Linux ksa-m1.blue 3.10.0-514.6.1.el7.x86_64 #1 SMP Wed Jan 18 13:06:36 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux</p>
<p>kubectl version
Client Version: <a href="http://version.Info">version.Info</a>{Major:&quot;1&quot;, Minor:&quot;9&quot;, GitVersion:&quot;v1.9.4&quot;, GitCommit:&quot;bee2d1505c4fe820744d26d41ecd3fdd4a3d6546&quot;, GitTreeState:&quot;clean&quot;, BuildDate:&quot;2018-03-12T16:29:47Z&quot;, GoVersion:&quot;go1.9.3&quot;, Compiler:&quot;gc&quot;, Platform:&quot;linux/amd64&quot;}
Server Version: <a href="http://version.Info">version.Info</a>{Major:&quot;1&quot;, Minor:&quot;9&quot;, GitVersion:&quot;v1.9.4&quot;, GitCommit:&quot;bee2d1505c4fe820744d26d41ecd3fdd4a3d6546&quot;, GitTreeState:&quot;clean&quot;, BuildDate:&quot;2018-03-12T16:21:35Z&quot;, GoVersion:&quot;go1.9.3&quot;, Compiler:&quot;gc&quot;, Platform:&quot;linux/amd64&quot;}</p>
<p>rpm -qa | egrep kube
kubernetes-cni-0.6.0-0.x86_64
kubelet-1.9.4-0.x86_64
kubectl-1.9.4-0.x86_64
kubeadm-1.9.4-0.x86_64</p>
<p>docker version
Client:
Version:         1.12.6
API version:     1.24
Package version: docker-1.12.6-71.git3e8e77d.el7.centos.1.x86_64
Go version:      go1.8.3
Git commit:      3e8e77d/1.12.6
Built:           Tue Jan 30 09:17:00 2018
OS/Arch:         linux/amd64</p>
<p>Server:
Version:         1.12.6
API version:     1.24
Package version: docker-1.12.6-71.git3e8e77d.el7.centos.1.x86_64
Go version:      go1.8.3
Git commit:      3e8e77d/1.12.6
Built:           Tue Jan 30 09:17:00 2018
OS/Arch:         linux/amd64</p>
</blockquote>
</blockquote>
<hr>
<h2 id="">常用命令</h2>
<pre><code class="language-Shell">kubectl get po -o wide --all-namespaces

# 查看 Master join Token
kubeadm token create --print-join-command

</code></pre>
<pre><code>kubeadm join ${ipaddr}:${proxy} --token 6y08dg.q977edbxcjepnq68 --discovery-token-ca-cert-hash sha256:003ade97af781e60aba97817f0330f512a531336e604950b694ebfa3fcd0b6cd
</code></pre>

    </body>
    </html>